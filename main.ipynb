{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing requirements\n",
    "- This can be done by creating a requirements.txt file and installing all the libraries in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple classification with MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "n_hidden = 128\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train.shape=(60000, 28, 28) & X_test.shape =(10000, 28, 28) '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "f\"{X_train.shape=} & {X_test.shape =} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row is a digit\n",
    "X_train = X_train.reshape(60000,784)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "X_test = X_test.reshape(10000,784)\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the input\n",
    "# Normalization helps with the gradient descent by providing equal updates to the weight vectors\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "## Convert the y variables to OHE variables\n",
    "## OHE for Y labels --> Really cool\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x310b24150>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = 1028\n",
    "print(np.where(Y_train[r,:]==1))\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(X_train[r,:].reshape((28,28)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " D1 (Dense)                  (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7850 (30.66 KB)\n",
      "Trainable params: 7850 (30.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 0s 791us/step - loss: 1.4051 - accuracy: 0.6571 - val_loss: 0.8976 - val_accuracy: 0.8245\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 621us/step - loss: 0.7913 - accuracy: 0.8314 - val_loss: 0.6550 - val_accuracy: 0.8616\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 619us/step - loss: 0.6397 - accuracy: 0.8533 - val_loss: 0.5587 - val_accuracy: 0.8746\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 618us/step - loss: 0.5673 - accuracy: 0.8634 - val_loss: 0.5057 - val_accuracy: 0.8806\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 617us/step - loss: 0.5236 - accuracy: 0.8702 - val_loss: 0.4720 - val_accuracy: 0.8838\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 620us/step - loss: 0.4936 - accuracy: 0.8743 - val_loss: 0.4480 - val_accuracy: 0.8880\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 623us/step - loss: 0.4716 - accuracy: 0.8781 - val_loss: 0.4302 - val_accuracy: 0.8909\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 624us/step - loss: 0.4545 - accuracy: 0.8811 - val_loss: 0.4161 - val_accuracy: 0.8926\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 617us/step - loss: 0.4407 - accuracy: 0.8840 - val_loss: 0.4049 - val_accuracy: 0.8940\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 615us/step - loss: 0.4293 - accuracy: 0.8856 - val_loss: 0.3954 - val_accuracy: 0.8967\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 620us/step - loss: 0.4197 - accuracy: 0.8879 - val_loss: 0.3876 - val_accuracy: 0.8985\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 617us/step - loss: 0.4115 - accuracy: 0.8900 - val_loss: 0.3806 - val_accuracy: 0.9003\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 614us/step - loss: 0.4042 - accuracy: 0.8915 - val_loss: 0.3747 - val_accuracy: 0.9005\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 615us/step - loss: 0.3979 - accuracy: 0.8926 - val_loss: 0.3695 - val_accuracy: 0.9018\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 612us/step - loss: 0.3922 - accuracy: 0.8941 - val_loss: 0.3648 - val_accuracy: 0.9027\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 628us/step - loss: 0.3872 - accuracy: 0.8956 - val_loss: 0.3605 - val_accuracy: 0.9040\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 631us/step - loss: 0.3825 - accuracy: 0.8963 - val_loss: 0.3567 - val_accuracy: 0.9052\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 628us/step - loss: 0.3784 - accuracy: 0.8972 - val_loss: 0.3533 - val_accuracy: 0.9058\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 621us/step - loss: 0.3745 - accuracy: 0.8982 - val_loss: 0.3501 - val_accuracy: 0.9070\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 623us/step - loss: 0.3710 - accuracy: 0.8988 - val_loss: 0.3472 - val_accuracy: 0.9064\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 623us/step - loss: 0.3676 - accuracy: 0.8997 - val_loss: 0.3445 - val_accuracy: 0.9069\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 622us/step - loss: 0.3646 - accuracy: 0.9001 - val_loss: 0.3421 - val_accuracy: 0.9077\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 660us/step - loss: 0.3618 - accuracy: 0.9011 - val_loss: 0.3396 - val_accuracy: 0.9082\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 697us/step - loss: 0.3592 - accuracy: 0.9016 - val_loss: 0.3376 - val_accuracy: 0.9088\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 615us/step - loss: 0.3566 - accuracy: 0.9020 - val_loss: 0.3355 - val_accuracy: 0.9093\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 615us/step - loss: 0.3543 - accuracy: 0.9025 - val_loss: 0.3335 - val_accuracy: 0.9096\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 619us/step - loss: 0.3521 - accuracy: 0.9029 - val_loss: 0.3318 - val_accuracy: 0.9100\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 622us/step - loss: 0.3500 - accuracy: 0.9032 - val_loss: 0.3301 - val_accuracy: 0.9104\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 616us/step - loss: 0.3480 - accuracy: 0.9038 - val_loss: 0.3285 - val_accuracy: 0.9104\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 622us/step - loss: 0.3461 - accuracy: 0.9043 - val_loss: 0.3270 - val_accuracy: 0.9108\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 619us/step - loss: 0.3443 - accuracy: 0.9046 - val_loss: 0.3255 - val_accuracy: 0.9112\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 616us/step - loss: 0.3426 - accuracy: 0.9049 - val_loss: 0.3242 - val_accuracy: 0.9110\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 663us/step - loss: 0.3409 - accuracy: 0.9055 - val_loss: 0.3228 - val_accuracy: 0.9111\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 624us/step - loss: 0.3394 - accuracy: 0.9062 - val_loss: 0.3215 - val_accuracy: 0.9118\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 620us/step - loss: 0.3379 - accuracy: 0.9065 - val_loss: 0.3203 - val_accuracy: 0.9120\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 612us/step - loss: 0.3365 - accuracy: 0.9063 - val_loss: 0.3192 - val_accuracy: 0.9120\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 620us/step - loss: 0.3351 - accuracy: 0.9076 - val_loss: 0.3181 - val_accuracy: 0.9119\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 615us/step - loss: 0.3338 - accuracy: 0.9076 - val_loss: 0.3171 - val_accuracy: 0.9126\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 623us/step - loss: 0.3325 - accuracy: 0.9078 - val_loss: 0.3161 - val_accuracy: 0.9127\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 622us/step - loss: 0.3313 - accuracy: 0.9082 - val_loss: 0.3151 - val_accuracy: 0.9136\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 619us/step - loss: 0.3301 - accuracy: 0.9089 - val_loss: 0.3141 - val_accuracy: 0.9137\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 628us/step - loss: 0.3290 - accuracy: 0.9086 - val_loss: 0.3132 - val_accuracy: 0.9140\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 636us/step - loss: 0.3279 - accuracy: 0.9093 - val_loss: 0.3124 - val_accuracy: 0.9139\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 633us/step - loss: 0.3268 - accuracy: 0.9092 - val_loss: 0.3115 - val_accuracy: 0.9143\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 624us/step - loss: 0.3258 - accuracy: 0.9096 - val_loss: 0.3107 - val_accuracy: 0.9143\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 625us/step - loss: 0.3248 - accuracy: 0.9102 - val_loss: 0.3100 - val_accuracy: 0.9145\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 632us/step - loss: 0.3239 - accuracy: 0.9104 - val_loss: 0.3093 - val_accuracy: 0.9147\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 648us/step - loss: 0.3229 - accuracy: 0.9107 - val_loss: 0.3085 - val_accuracy: 0.9148\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 642us/step - loss: 0.3220 - accuracy: 0.9107 - val_loss: 0.3078 - val_accuracy: 0.9147\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 706us/step - loss: 0.3211 - accuracy: 0.9113 - val_loss: 0.3070 - val_accuracy: 0.9154\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add the layers to the model\n",
    "# it means that the input is a tensor of 784 -dimension\n",
    "# this is the way how we write it\n",
    "model.add(layers.Input(shape=(784,)))\n",
    "model.add(layers.Dense(units=10, activation = 'softmax', name = 'D1'))\n",
    "# Print the summary of the model\n",
    "model.summary()\n",
    "model.compile(loss=  'categorical_crossentropy', metrics = 'accuracy', optimizer = 'sgd')\n",
    "m0 = model.fit(X_train, Y_train, epochs =50, batch_size = 128, validation_split = 0.2, verbose = True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Epoch is one complete traversal through the data\n",
    "- batch size = 128 means, at a time 128 examples of {Feature: Output} will be used to calculate the gradient. Total examples in training data = 60000 * 0.8 (accounting for validation data)/ 128 = 375\n",
    "- 375 indicates number of gradient descent steps that are taken at each epoc\n",
    "- The validation data in tensorflow remains same for each epoch: https://stackoverflow.com/questions/48810813/how-to-extract-train-and-validation-sets-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 382us/step - loss: 0.3069 - accuracy: 0.9165\n",
      "0.9164999723434448\n",
      "313/313 [==============================] - 0s 299us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       980\n",
      "           1       0.96      0.97      0.96      1135\n",
      "           2       0.93      0.88      0.90      1032\n",
      "           3       0.90      0.91      0.90      1010\n",
      "           4       0.90      0.93      0.92       982\n",
      "           5       0.91      0.85      0.88       892\n",
      "           6       0.93      0.95      0.94       958\n",
      "           7       0.93      0.91      0.92      1028\n",
      "           8       0.87      0.89      0.88       974\n",
      "           9       0.90      0.89      0.89      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print(test_acc)\n",
    "print(classification_report(y_true = np.where(Y_test==1)[1], y_pred= np.argmax(model.predict(X_test), axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 0s 829us/step - loss: 1.5638 - accuracy: 0.5645 - val_loss: 0.9588 - val_accuracy: 0.7947\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 825us/step - loss: 0.7685 - accuracy: 0.8153 - val_loss: 0.5895 - val_accuracy: 0.8573\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 711us/step - loss: 0.5601 - accuracy: 0.8558 - val_loss: 0.4745 - val_accuracy: 0.8773\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.4759 - accuracy: 0.8733 - val_loss: 0.4178 - val_accuracy: 0.8880\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 673us/step - loss: 0.4296 - accuracy: 0.8827 - val_loss: 0.3851 - val_accuracy: 0.8938\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 656us/step - loss: 0.3997 - accuracy: 0.8898 - val_loss: 0.3625 - val_accuracy: 0.9001\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 675us/step - loss: 0.3785 - accuracy: 0.8949 - val_loss: 0.3462 - val_accuracy: 0.9024\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.3624 - accuracy: 0.8984 - val_loss: 0.3337 - val_accuracy: 0.9055\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 674us/step - loss: 0.3495 - accuracy: 0.9017 - val_loss: 0.3238 - val_accuracy: 0.9082\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 676us/step - loss: 0.3389 - accuracy: 0.9037 - val_loss: 0.3157 - val_accuracy: 0.9112\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 660us/step - loss: 0.3299 - accuracy: 0.9063 - val_loss: 0.3087 - val_accuracy: 0.9124\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 657us/step - loss: 0.3223 - accuracy: 0.9078 - val_loss: 0.3016 - val_accuracy: 0.9134\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 662us/step - loss: 0.3153 - accuracy: 0.9101 - val_loss: 0.2971 - val_accuracy: 0.9147\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 672us/step - loss: 0.3091 - accuracy: 0.9113 - val_loss: 0.2916 - val_accuracy: 0.9158\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 679us/step - loss: 0.3035 - accuracy: 0.9131 - val_loss: 0.2877 - val_accuracy: 0.9163\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 647us/step - loss: 0.2983 - accuracy: 0.9147 - val_loss: 0.2838 - val_accuracy: 0.9183\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 649us/step - loss: 0.2935 - accuracy: 0.9162 - val_loss: 0.2791 - val_accuracy: 0.9201\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 653us/step - loss: 0.2890 - accuracy: 0.9179 - val_loss: 0.2754 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 651us/step - loss: 0.2850 - accuracy: 0.9185 - val_loss: 0.2720 - val_accuracy: 0.9209\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 660us/step - loss: 0.2811 - accuracy: 0.9200 - val_loss: 0.2686 - val_accuracy: 0.9232\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 649us/step - loss: 0.2773 - accuracy: 0.9208 - val_loss: 0.2660 - val_accuracy: 0.9236\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 653us/step - loss: 0.2737 - accuracy: 0.9214 - val_loss: 0.2631 - val_accuracy: 0.9243\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 653us/step - loss: 0.2703 - accuracy: 0.9227 - val_loss: 0.2609 - val_accuracy: 0.9250\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 644us/step - loss: 0.2671 - accuracy: 0.9234 - val_loss: 0.2575 - val_accuracy: 0.9262\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 650us/step - loss: 0.2639 - accuracy: 0.9249 - val_loss: 0.2551 - val_accuracy: 0.9270\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 651us/step - loss: 0.2609 - accuracy: 0.9249 - val_loss: 0.2527 - val_accuracy: 0.9265\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 651us/step - loss: 0.2581 - accuracy: 0.9264 - val_loss: 0.2502 - val_accuracy: 0.9275\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 646us/step - loss: 0.2553 - accuracy: 0.9271 - val_loss: 0.2483 - val_accuracy: 0.9283\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 660us/step - loss: 0.2527 - accuracy: 0.9284 - val_loss: 0.2460 - val_accuracy: 0.9298\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 655us/step - loss: 0.2500 - accuracy: 0.9286 - val_loss: 0.2442 - val_accuracy: 0.9304\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 639us/step - loss: 0.2473 - accuracy: 0.9298 - val_loss: 0.2421 - val_accuracy: 0.9307\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 643us/step - loss: 0.2449 - accuracy: 0.9301 - val_loss: 0.2401 - val_accuracy: 0.9326\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 649us/step - loss: 0.2426 - accuracy: 0.9308 - val_loss: 0.2384 - val_accuracy: 0.9328\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 647us/step - loss: 0.2403 - accuracy: 0.9316 - val_loss: 0.2365 - val_accuracy: 0.9329\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 650us/step - loss: 0.2381 - accuracy: 0.9323 - val_loss: 0.2350 - val_accuracy: 0.9329\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 650us/step - loss: 0.2358 - accuracy: 0.9329 - val_loss: 0.2338 - val_accuracy: 0.9336\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 651us/step - loss: 0.2338 - accuracy: 0.9335 - val_loss: 0.2322 - val_accuracy: 0.9342\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 654us/step - loss: 0.2317 - accuracy: 0.9344 - val_loss: 0.2304 - val_accuracy: 0.9356\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 643us/step - loss: 0.2297 - accuracy: 0.9346 - val_loss: 0.2286 - val_accuracy: 0.9359\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 649us/step - loss: 0.2279 - accuracy: 0.9354 - val_loss: 0.2272 - val_accuracy: 0.9364\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 646us/step - loss: 0.2260 - accuracy: 0.9358 - val_loss: 0.2263 - val_accuracy: 0.9358\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 653us/step - loss: 0.2242 - accuracy: 0.9365 - val_loss: 0.2253 - val_accuracy: 0.9361\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 724us/step - loss: 0.2226 - accuracy: 0.9372 - val_loss: 0.2240 - val_accuracy: 0.9367\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 654us/step - loss: 0.2208 - accuracy: 0.9374 - val_loss: 0.2221 - val_accuracy: 0.9373\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 651us/step - loss: 0.2192 - accuracy: 0.9376 - val_loss: 0.2207 - val_accuracy: 0.9375\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 659us/step - loss: 0.2175 - accuracy: 0.9385 - val_loss: 0.2198 - val_accuracy: 0.9381\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 649us/step - loss: 0.2159 - accuracy: 0.9384 - val_loss: 0.2188 - val_accuracy: 0.9383\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 648us/step - loss: 0.2143 - accuracy: 0.9398 - val_loss: 0.2174 - val_accuracy: 0.9391\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 645us/step - loss: 0.2129 - accuracy: 0.9398 - val_loss: 0.2162 - val_accuracy: 0.9394\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 646us/step - loss: 0.2113 - accuracy: 0.9399 - val_loss: 0.2159 - val_accuracy: 0.9391\n"
     ]
    }
   ],
   "source": [
    "# improving the model by adding one dense layer\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (784,)),\n",
    "        layers.Dense(units = 20, activation = 'relu', name = 'D1'),\n",
    "        layers.Dense(units = 10, activation = 'softmax', name = 'D2')\n",
    "    ]\n",
    "    )\n",
    "model.compile(optimizer = 'SGD', loss =  'categorical_crossentropy', metrics = 'accuracy')\n",
    "%timeit\n",
    "m1 = model.fit(X_train, Y_train, validation_split = 0.2, batch_size = 128, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 0s 874us/step - loss: 1.9152 - accuracy: 0.3899 - val_loss: 1.3692 - val_accuracy: 0.6399\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 708us/step - loss: 1.0033 - accuracy: 0.7274 - val_loss: 0.7144 - val_accuracy: 0.8061\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 709us/step - loss: 0.6465 - accuracy: 0.8159 - val_loss: 0.5247 - val_accuracy: 0.8570\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.5082 - accuracy: 0.8573 - val_loss: 0.4315 - val_accuracy: 0.8824\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 707us/step - loss: 0.4313 - accuracy: 0.8791 - val_loss: 0.3757 - val_accuracy: 0.8966\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.3844 - accuracy: 0.8921 - val_loss: 0.3412 - val_accuracy: 0.9061\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 703us/step - loss: 0.3531 - accuracy: 0.9001 - val_loss: 0.3182 - val_accuracy: 0.9112\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 710us/step - loss: 0.3309 - accuracy: 0.9061 - val_loss: 0.3009 - val_accuracy: 0.9147\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 706us/step - loss: 0.3138 - accuracy: 0.9111 - val_loss: 0.2871 - val_accuracy: 0.9178\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 706us/step - loss: 0.3000 - accuracy: 0.9139 - val_loss: 0.2764 - val_accuracy: 0.9219\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.2887 - accuracy: 0.9181 - val_loss: 0.2679 - val_accuracy: 0.9243\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.2787 - accuracy: 0.9204 - val_loss: 0.2589 - val_accuracy: 0.9268\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 701us/step - loss: 0.2701 - accuracy: 0.9223 - val_loss: 0.2520 - val_accuracy: 0.9292\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 728us/step - loss: 0.2619 - accuracy: 0.9253 - val_loss: 0.2442 - val_accuracy: 0.9318\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 754us/step - loss: 0.2552 - accuracy: 0.9273 - val_loss: 0.2401 - val_accuracy: 0.9331\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 705us/step - loss: 0.2483 - accuracy: 0.9290 - val_loss: 0.2342 - val_accuracy: 0.9341\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 703us/step - loss: 0.2426 - accuracy: 0.9310 - val_loss: 0.2293 - val_accuracy: 0.9352\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.2371 - accuracy: 0.9324 - val_loss: 0.2264 - val_accuracy: 0.9363\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 703us/step - loss: 0.2316 - accuracy: 0.9340 - val_loss: 0.2217 - val_accuracy: 0.9378\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 709us/step - loss: 0.2270 - accuracy: 0.9358 - val_loss: 0.2163 - val_accuracy: 0.9407\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 698us/step - loss: 0.2224 - accuracy: 0.9366 - val_loss: 0.2130 - val_accuracy: 0.9398\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 706us/step - loss: 0.2178 - accuracy: 0.9376 - val_loss: 0.2095 - val_accuracy: 0.9413\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 703us/step - loss: 0.2138 - accuracy: 0.9389 - val_loss: 0.2075 - val_accuracy: 0.9423\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.2100 - accuracy: 0.9403 - val_loss: 0.2036 - val_accuracy: 0.9428\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.2062 - accuracy: 0.9410 - val_loss: 0.2001 - val_accuracy: 0.9441\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 705us/step - loss: 0.2027 - accuracy: 0.9420 - val_loss: 0.1973 - val_accuracy: 0.9452\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 700us/step - loss: 0.1991 - accuracy: 0.9432 - val_loss: 0.1954 - val_accuracy: 0.9456\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 716us/step - loss: 0.1956 - accuracy: 0.9434 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.1926 - accuracy: 0.9445 - val_loss: 0.1912 - val_accuracy: 0.9479\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 709us/step - loss: 0.1894 - accuracy: 0.9451 - val_loss: 0.1881 - val_accuracy: 0.9482\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.1861 - accuracy: 0.9466 - val_loss: 0.1865 - val_accuracy: 0.9486\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 699us/step - loss: 0.1834 - accuracy: 0.9470 - val_loss: 0.1846 - val_accuracy: 0.9492\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 706us/step - loss: 0.1807 - accuracy: 0.9482 - val_loss: 0.1834 - val_accuracy: 0.9502\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.1782 - accuracy: 0.9487 - val_loss: 0.1807 - val_accuracy: 0.9507\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 708us/step - loss: 0.1754 - accuracy: 0.9502 - val_loss: 0.1778 - val_accuracy: 0.9509\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 701us/step - loss: 0.1731 - accuracy: 0.9496 - val_loss: 0.1784 - val_accuracy: 0.9518\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 703us/step - loss: 0.1706 - accuracy: 0.9507 - val_loss: 0.1753 - val_accuracy: 0.9528\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 699us/step - loss: 0.1680 - accuracy: 0.9526 - val_loss: 0.1747 - val_accuracy: 0.9522\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 706us/step - loss: 0.1659 - accuracy: 0.9523 - val_loss: 0.1716 - val_accuracy: 0.9534\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 740us/step - loss: 0.1637 - accuracy: 0.9531 - val_loss: 0.1720 - val_accuracy: 0.9536\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 712us/step - loss: 0.1616 - accuracy: 0.9536 - val_loss: 0.1692 - val_accuracy: 0.9545\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 700us/step - loss: 0.1594 - accuracy: 0.9545 - val_loss: 0.1688 - val_accuracy: 0.9535\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.1571 - accuracy: 0.9551 - val_loss: 0.1690 - val_accuracy: 0.9536\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 707us/step - loss: 0.1553 - accuracy: 0.9557 - val_loss: 0.1649 - val_accuracy: 0.9550\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 710us/step - loss: 0.1533 - accuracy: 0.9562 - val_loss: 0.1646 - val_accuracy: 0.9555\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 709us/step - loss: 0.1515 - accuracy: 0.9571 - val_loss: 0.1640 - val_accuracy: 0.9544\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.1498 - accuracy: 0.9572 - val_loss: 0.1632 - val_accuracy: 0.9544\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.1480 - accuracy: 0.9580 - val_loss: 0.1611 - val_accuracy: 0.9556\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 706us/step - loss: 0.1462 - accuracy: 0.9582 - val_loss: 0.1601 - val_accuracy: 0.9552\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 707us/step - loss: 0.1446 - accuracy: 0.9585 - val_loss: 0.1588 - val_accuracy: 0.9555\n"
     ]
    }
   ],
   "source": [
    "## Add one more dense layer\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (784,)),\n",
    "        layers.Dense(units = 32, activation = 'relu', name = 'D1'),\n",
    "        layers.Dense(units = 16, activation = 'relu', name = 'D2'),\n",
    "\n",
    "        layers.Dense(units = 10, activation = 'softmax', name = 'D3')\n",
    "    ]\n",
    "    )\n",
    "model.compile(optimizer = 'SGD', loss =  'categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "m2 = model.fit(X_train, Y_train, validation_split = 0.2, batch_size = 128, epochs = 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer and Dropout\n",
    "- Dropout is a way to tackle overfitting similar to regularization\n",
    "- The idea behind dropout is that some output nodes are randomly dropped such that they don't take part in the model training\n",
    "- During <B>Training</B>, a dropout ratio is selected 'p'. p = 0 means all are dropped, p=1 means none is dropped\n",
    "- During testing: The weights will be overestimated for the neurons that were kept. Therefore, the weights are multiplied by p \n",
    "\n",
    "https://medium.com/analytics-vidhya/understanding-dropout-abe00504be82\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 0s 877us/step - loss: 2.2103 - accuracy: 0.1777 - val_loss: 1.9755 - val_accuracy: 0.4114\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 736us/step - loss: 1.8464 - accuracy: 0.3695 - val_loss: 1.4374 - val_accuracy: 0.6572\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 718us/step - loss: 1.4289 - accuracy: 0.5423 - val_loss: 0.9574 - val_accuracy: 0.7593\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 748us/step - loss: 1.1513 - accuracy: 0.6233 - val_loss: 0.7318 - val_accuracy: 0.8164\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 746us/step - loss: 1.0061 - accuracy: 0.6709 - val_loss: 0.6190 - val_accuracy: 0.8433\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 737us/step - loss: 0.9203 - accuracy: 0.6991 - val_loss: 0.5518 - val_accuracy: 0.8598\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 729us/step - loss: 0.8571 - accuracy: 0.7206 - val_loss: 0.5017 - val_accuracy: 0.8736\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 811us/step - loss: 0.8090 - accuracy: 0.7387 - val_loss: 0.4646 - val_accuracy: 0.8798\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 720us/step - loss: 0.7775 - accuracy: 0.7484 - val_loss: 0.4364 - val_accuracy: 0.8861\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 726us/step - loss: 0.7455 - accuracy: 0.7604 - val_loss: 0.4130 - val_accuracy: 0.8901\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 781us/step - loss: 0.7197 - accuracy: 0.7703 - val_loss: 0.3933 - val_accuracy: 0.8922\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 722us/step - loss: 0.6958 - accuracy: 0.7773 - val_loss: 0.3760 - val_accuracy: 0.8995\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 778us/step - loss: 0.6783 - accuracy: 0.7831 - val_loss: 0.3578 - val_accuracy: 0.9018\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 759us/step - loss: 0.6610 - accuracy: 0.7913 - val_loss: 0.3479 - val_accuracy: 0.9048\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 849us/step - loss: 0.6404 - accuracy: 0.7949 - val_loss: 0.3321 - val_accuracy: 0.9086\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 750us/step - loss: 0.6269 - accuracy: 0.8017 - val_loss: 0.3245 - val_accuracy: 0.9107\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 716us/step - loss: 0.6181 - accuracy: 0.8086 - val_loss: 0.3162 - val_accuracy: 0.9133\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 697us/step - loss: 0.6032 - accuracy: 0.8128 - val_loss: 0.3079 - val_accuracy: 0.9151\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 746us/step - loss: 0.5928 - accuracy: 0.8162 - val_loss: 0.3020 - val_accuracy: 0.9172\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 723us/step - loss: 0.5814 - accuracy: 0.8190 - val_loss: 0.2943 - val_accuracy: 0.9180\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 727us/step - loss: 0.5744 - accuracy: 0.8219 - val_loss: 0.2883 - val_accuracy: 0.9195\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 706us/step - loss: 0.5612 - accuracy: 0.8244 - val_loss: 0.2829 - val_accuracy: 0.9203\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 712us/step - loss: 0.5451 - accuracy: 0.8303 - val_loss: 0.2791 - val_accuracy: 0.9210\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 714us/step - loss: 0.5476 - accuracy: 0.8301 - val_loss: 0.2726 - val_accuracy: 0.9232\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 716us/step - loss: 0.5352 - accuracy: 0.8351 - val_loss: 0.2684 - val_accuracy: 0.9238\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 733us/step - loss: 0.5256 - accuracy: 0.8373 - val_loss: 0.2661 - val_accuracy: 0.9250\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 719us/step - loss: 0.5227 - accuracy: 0.8393 - val_loss: 0.2604 - val_accuracy: 0.9261\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.5209 - accuracy: 0.8395 - val_loss: 0.2581 - val_accuracy: 0.9262\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 705us/step - loss: 0.5133 - accuracy: 0.8416 - val_loss: 0.2564 - val_accuracy: 0.9267\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 707us/step - loss: 0.5092 - accuracy: 0.8420 - val_loss: 0.2518 - val_accuracy: 0.9277\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 697us/step - loss: 0.5058 - accuracy: 0.8442 - val_loss: 0.2485 - val_accuracy: 0.9288\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 699us/step - loss: 0.5022 - accuracy: 0.8454 - val_loss: 0.2472 - val_accuracy: 0.9283\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 711us/step - loss: 0.4918 - accuracy: 0.8464 - val_loss: 0.2440 - val_accuracy: 0.9295\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 701us/step - loss: 0.4933 - accuracy: 0.8456 - val_loss: 0.2403 - val_accuracy: 0.9317\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 698us/step - loss: 0.4859 - accuracy: 0.8489 - val_loss: 0.2379 - val_accuracy: 0.9317\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 689us/step - loss: 0.4824 - accuracy: 0.8483 - val_loss: 0.2360 - val_accuracy: 0.9320\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 703us/step - loss: 0.4810 - accuracy: 0.8494 - val_loss: 0.2323 - val_accuracy: 0.9325\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 756us/step - loss: 0.4791 - accuracy: 0.8512 - val_loss: 0.2325 - val_accuracy: 0.9329\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 730us/step - loss: 0.4733 - accuracy: 0.8491 - val_loss: 0.2312 - val_accuracy: 0.9327\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 729us/step - loss: 0.4701 - accuracy: 0.8515 - val_loss: 0.2309 - val_accuracy: 0.9334\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 805us/step - loss: 0.4754 - accuracy: 0.8497 - val_loss: 0.2277 - val_accuracy: 0.9347\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 758us/step - loss: 0.4715 - accuracy: 0.8522 - val_loss: 0.2258 - val_accuracy: 0.9346\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 703us/step - loss: 0.4709 - accuracy: 0.8542 - val_loss: 0.2239 - val_accuracy: 0.9351\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 703us/step - loss: 0.4630 - accuracy: 0.8553 - val_loss: 0.2236 - val_accuracy: 0.9357\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 828us/step - loss: 0.4672 - accuracy: 0.8528 - val_loss: 0.2221 - val_accuracy: 0.9372\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 697us/step - loss: 0.4568 - accuracy: 0.8562 - val_loss: 0.2203 - val_accuracy: 0.9377\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 747us/step - loss: 0.4599 - accuracy: 0.8565 - val_loss: 0.2187 - val_accuracy: 0.9367\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 698us/step - loss: 0.4560 - accuracy: 0.8576 - val_loss: 0.2180 - val_accuracy: 0.9383\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 702us/step - loss: 0.4525 - accuracy: 0.8584 - val_loss: 0.2181 - val_accuracy: 0.9387\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 737us/step - loss: 0.4499 - accuracy: 0.8590 - val_loss: 0.2168 - val_accuracy: 0.9383\n"
     ]
    }
   ],
   "source": [
    "## Add one more dense layer\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (784,)),\n",
    "        layers.Dense(units = 32, activation = 'relu', name = 'D1'),\n",
    "        tf.keras.layers.Dropout(rate = 0.5, seed = 42),\n",
    "        layers.Dense(units = 16, activation = 'relu', name = 'D2'),\n",
    "\n",
    "        layers.Dense(units = 10, activation = 'softmax', name = 'D3')\n",
    "    ]\n",
    "    )\n",
    "model.compile(optimizer = 'SGD', loss =  'categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "m3 = model.fit(X_train, Y_train, validation_split = 0.2, batch_size = 128, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6045 - accuracy: 0.8281 - val_loss: 0.2819 - val_accuracy: 0.9193\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 870us/step - loss: 0.2726 - accuracy: 0.9229 - val_loss: 0.2295 - val_accuracy: 0.9352\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 989us/step - loss: 0.2224 - accuracy: 0.9372 - val_loss: 0.2079 - val_accuracy: 0.9414\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 883us/step - loss: 0.1933 - accuracy: 0.9447 - val_loss: 0.1825 - val_accuracy: 0.9475\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 870us/step - loss: 0.1715 - accuracy: 0.9509 - val_loss: 0.1775 - val_accuracy: 0.9482\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 896us/step - loss: 0.1551 - accuracy: 0.9548 - val_loss: 0.1731 - val_accuracy: 0.9492\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 889us/step - loss: 0.1420 - accuracy: 0.9585 - val_loss: 0.1615 - val_accuracy: 0.9529\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 897us/step - loss: 0.1325 - accuracy: 0.9614 - val_loss: 0.1543 - val_accuracy: 0.9570\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 895us/step - loss: 0.1228 - accuracy: 0.9645 - val_loss: 0.1580 - val_accuracy: 0.9548\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.1145 - accuracy: 0.9667 - val_loss: 0.1446 - val_accuracy: 0.9586\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 893us/step - loss: 0.1090 - accuracy: 0.9673 - val_loss: 0.1461 - val_accuracy: 0.9578\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 880us/step - loss: 0.1014 - accuracy: 0.9705 - val_loss: 0.1415 - val_accuracy: 0.9592\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 861us/step - loss: 0.0957 - accuracy: 0.9717 - val_loss: 0.1438 - val_accuracy: 0.9592\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 883us/step - loss: 0.0911 - accuracy: 0.9728 - val_loss: 0.1491 - val_accuracy: 0.9571\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 873us/step - loss: 0.0868 - accuracy: 0.9743 - val_loss: 0.1482 - val_accuracy: 0.9590\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 873us/step - loss: 0.0821 - accuracy: 0.9754 - val_loss: 0.1405 - val_accuracy: 0.9612\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 876us/step - loss: 0.0785 - accuracy: 0.9760 - val_loss: 0.1414 - val_accuracy: 0.9605\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 866us/step - loss: 0.0737 - accuracy: 0.9777 - val_loss: 0.1428 - val_accuracy: 0.9587\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 858us/step - loss: 0.0708 - accuracy: 0.9782 - val_loss: 0.1407 - val_accuracy: 0.9611\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 871us/step - loss: 0.0678 - accuracy: 0.9800 - val_loss: 0.1417 - val_accuracy: 0.9607\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 872us/step - loss: 0.0651 - accuracy: 0.9801 - val_loss: 0.1433 - val_accuracy: 0.9606\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 869us/step - loss: 0.0621 - accuracy: 0.9807 - val_loss: 0.1409 - val_accuracy: 0.9613\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 878us/step - loss: 0.0605 - accuracy: 0.9817 - val_loss: 0.1356 - val_accuracy: 0.9628\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 873us/step - loss: 0.0571 - accuracy: 0.9830 - val_loss: 0.1382 - val_accuracy: 0.9608\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 857us/step - loss: 0.0543 - accuracy: 0.9835 - val_loss: 0.1526 - val_accuracy: 0.9591\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 898us/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 0.1472 - val_accuracy: 0.9608\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 999us/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.1448 - val_accuracy: 0.9624\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 877us/step - loss: 0.0490 - accuracy: 0.9852 - val_loss: 0.1441 - val_accuracy: 0.9628\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 958us/step - loss: 0.0464 - accuracy: 0.9864 - val_loss: 0.1489 - val_accuracy: 0.9607\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 899us/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.1508 - val_accuracy: 0.9621\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 932us/step - loss: 0.0433 - accuracy: 0.9870 - val_loss: 0.1536 - val_accuracy: 0.9611\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 0.1534 - val_accuracy: 0.9619\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 857us/step - loss: 0.0383 - accuracy: 0.9890 - val_loss: 0.1488 - val_accuracy: 0.9614\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 853us/step - loss: 0.0387 - accuracy: 0.9888 - val_loss: 0.1548 - val_accuracy: 0.9617\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 875us/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.1746 - val_accuracy: 0.9579\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 875us/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 0.1637 - val_accuracy: 0.9608\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 865us/step - loss: 0.0345 - accuracy: 0.9899 - val_loss: 0.1627 - val_accuracy: 0.9614\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 872us/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.1606 - val_accuracy: 0.9613\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 868us/step - loss: 0.0310 - accuracy: 0.9913 - val_loss: 0.1653 - val_accuracy: 0.9628\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 875us/step - loss: 0.0288 - accuracy: 0.9920 - val_loss: 0.1667 - val_accuracy: 0.9628\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 852us/step - loss: 0.0279 - accuracy: 0.9922 - val_loss: 0.1703 - val_accuracy: 0.9605\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 984us/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.1695 - val_accuracy: 0.9611\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 965us/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.1721 - val_accuracy: 0.9622\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 891us/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.1704 - val_accuracy: 0.9621\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 894us/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.1833 - val_accuracy: 0.9602\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 864us/step - loss: 0.0233 - accuracy: 0.9937 - val_loss: 0.1849 - val_accuracy: 0.9611\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 861us/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.1866 - val_accuracy: 0.9607\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 868us/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.1971 - val_accuracy: 0.9587\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 860us/step - loss: 0.0201 - accuracy: 0.9946 - val_loss: 0.1889 - val_accuracy: 0.9609\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 880us/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.1875 - val_accuracy: 0.9625\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 971us/step - loss: 0.5684 - accuracy: 0.8459 - val_loss: 0.2743 - val_accuracy: 0.9240\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 814us/step - loss: 0.2634 - accuracy: 0.9248 - val_loss: 0.2207 - val_accuracy: 0.9382\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 804us/step - loss: 0.2131 - accuracy: 0.9392 - val_loss: 0.1879 - val_accuracy: 0.9479\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 801us/step - loss: 0.1817 - accuracy: 0.9483 - val_loss: 0.1751 - val_accuracy: 0.9508\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 817us/step - loss: 0.1619 - accuracy: 0.9538 - val_loss: 0.1620 - val_accuracy: 0.9528\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 807us/step - loss: 0.1466 - accuracy: 0.9582 - val_loss: 0.1630 - val_accuracy: 0.9526\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 796us/step - loss: 0.1346 - accuracy: 0.9613 - val_loss: 0.1537 - val_accuracy: 0.9568\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 795us/step - loss: 0.1257 - accuracy: 0.9634 - val_loss: 0.1523 - val_accuracy: 0.9574\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 806us/step - loss: 0.1171 - accuracy: 0.9661 - val_loss: 0.1422 - val_accuracy: 0.9597\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 835us/step - loss: 0.1096 - accuracy: 0.9683 - val_loss: 0.1431 - val_accuracy: 0.9595\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 825us/step - loss: 0.1036 - accuracy: 0.9699 - val_loss: 0.1361 - val_accuracy: 0.9611\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 887us/step - loss: 0.0982 - accuracy: 0.9712 - val_loss: 0.1305 - val_accuracy: 0.9628\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 843us/step - loss: 0.0933 - accuracy: 0.9736 - val_loss: 0.1360 - val_accuracy: 0.9607\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 831us/step - loss: 0.0887 - accuracy: 0.9742 - val_loss: 0.1272 - val_accuracy: 0.9641\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 808us/step - loss: 0.0842 - accuracy: 0.9759 - val_loss: 0.1324 - val_accuracy: 0.9614\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 801us/step - loss: 0.0801 - accuracy: 0.9768 - val_loss: 0.1311 - val_accuracy: 0.9617\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 803us/step - loss: 0.0765 - accuracy: 0.9775 - val_loss: 0.1318 - val_accuracy: 0.9621\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 817us/step - loss: 0.0726 - accuracy: 0.9789 - val_loss: 0.1303 - val_accuracy: 0.9628\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 819us/step - loss: 0.0699 - accuracy: 0.9794 - val_loss: 0.1272 - val_accuracy: 0.9635\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 800us/step - loss: 0.0669 - accuracy: 0.9803 - val_loss: 0.1313 - val_accuracy: 0.9627\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 806us/step - loss: 0.0644 - accuracy: 0.9811 - val_loss: 0.1289 - val_accuracy: 0.9635\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 801us/step - loss: 0.0620 - accuracy: 0.9818 - val_loss: 0.1369 - val_accuracy: 0.9626\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 810us/step - loss: 0.0587 - accuracy: 0.9833 - val_loss: 0.1343 - val_accuracy: 0.9630\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 819us/step - loss: 0.0570 - accuracy: 0.9834 - val_loss: 0.1407 - val_accuracy: 0.9617\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 821us/step - loss: 0.0547 - accuracy: 0.9841 - val_loss: 0.1343 - val_accuracy: 0.9645\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 834us/step - loss: 0.0528 - accuracy: 0.9848 - val_loss: 0.1380 - val_accuracy: 0.9622\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 816us/step - loss: 0.0505 - accuracy: 0.9856 - val_loss: 0.1392 - val_accuracy: 0.9628\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 796us/step - loss: 0.0491 - accuracy: 0.9862 - val_loss: 0.1374 - val_accuracy: 0.9633\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 796us/step - loss: 0.0473 - accuracy: 0.9862 - val_loss: 0.1387 - val_accuracy: 0.9628\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 831us/step - loss: 0.0453 - accuracy: 0.9866 - val_loss: 0.1420 - val_accuracy: 0.9628\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 826us/step - loss: 0.0433 - accuracy: 0.9876 - val_loss: 0.1472 - val_accuracy: 0.9628\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 838us/step - loss: 0.0421 - accuracy: 0.9877 - val_loss: 0.1462 - val_accuracy: 0.9630\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 817us/step - loss: 0.0405 - accuracy: 0.9885 - val_loss: 0.1495 - val_accuracy: 0.9624\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 889us/step - loss: 0.0391 - accuracy: 0.9889 - val_loss: 0.1487 - val_accuracy: 0.9643\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 838us/step - loss: 0.0372 - accuracy: 0.9892 - val_loss: 0.1493 - val_accuracy: 0.9631\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 842us/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 0.1547 - val_accuracy: 0.9612\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 795us/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.1596 - val_accuracy: 0.9647\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 849us/step - loss: 0.0335 - accuracy: 0.9904 - val_loss: 0.1657 - val_accuracy: 0.9613\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 796us/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.1634 - val_accuracy: 0.9622\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 800us/step - loss: 0.0315 - accuracy: 0.9913 - val_loss: 0.1598 - val_accuracy: 0.9640\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 796us/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.1609 - val_accuracy: 0.9634\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 812us/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.1692 - val_accuracy: 0.9622\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 803us/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.1786 - val_accuracy: 0.9603\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 796us/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.1687 - val_accuracy: 0.9634\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 876us/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.1797 - val_accuracy: 0.9606\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 791us/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.1793 - val_accuracy: 0.9614\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 803us/step - loss: 0.0245 - accuracy: 0.9930 - val_loss: 0.1804 - val_accuracy: 0.9622\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 796us/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.1858 - val_accuracy: 0.9613\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 831us/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.1826 - val_accuracy: 0.9623\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 872us/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.1908 - val_accuracy: 0.9620\n"
     ]
    }
   ],
   "source": [
    "# Effect of optimization algorithms on the training process\n",
    "## Add one more dense layer\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (784,)),\n",
    "        layers.Dense(units = 32, activation = 'relu', name = 'D1'),\n",
    "        layers.Dense(units = 16, activation = 'relu', name = 'D2'),\n",
    "\n",
    "        layers.Dense(units = 10, activation = 'softmax', name = 'D3')\n",
    "    ]\n",
    "    )\n",
    "model.compile(optimizer = 'Adam', loss =  'categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "m4 = model.fit(X_train, Y_train, validation_split = 0.2, batch_size = 128, epochs = 50)\n",
    "\n",
    "# Effect of optimization algorithms on the training process\n",
    "## Add one more dense layer\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (784,)),\n",
    "        layers.Dense(units = 32, activation = 'relu', name = 'D1'),\n",
    "        layers.Dense(units = 16, activation = 'relu', name = 'D2'),\n",
    "\n",
    "        layers.Dense(units = 10, activation = 'softmax', name = 'D3')\n",
    "    ]\n",
    "    )\n",
    "model.compile(optimizer = 'RMSprop', loss =  'categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "m5 = model.fit(X_train, Y_train, validation_split = 0.2, batch_size = 128, epochs = 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "This is used to combat the overfitting problem. It helps in two ways:\n",
    "- Choosing a simple model means easier to train (less computationally demanding)\n",
    "- Better generalization power\n",
    "\n",
    "Model is nothing but a vector of weights. Complexity can be controlled by setting some weights to either zero or very close to zero.\n",
    "\n",
    "The objective function of training is : $Obj\\space = min(Loss_{training} | Model)$\n",
    "\n",
    "\n",
    "To incorporate the regularizartion, this is modified to :\n",
    "$Obj\\space = min(Loss_{training} | Model) \\space + \\lambda* Complexity_{model}$\n",
    "\n",
    "Here $\\lambda $ can be used as a hyperparameter to indicate how much we want to weigh in complexity in the objective function\n",
    "\n",
    "\n",
    "Types of regularizers: https://stats.stackexchange.com/questions/383310/what-is-the-difference-between-kernel-bias-and-activity-regulizers-and-when-t\n",
    "\n",
    "- There are three type of regularizers in Keras:\n",
    "    You have the regression equation 𝑦=𝑊𝑥+𝑏, where 𝑥 is the input, 𝑊 the weights matrix and 𝑏 the bias.\n",
    "\n",
    "    - Kernel Regularizer: Tries to reduce the weights 𝑊 (excluding bias).\n",
    "    - Bias Regularizer: Tries to reduce the bias 𝑏.\n",
    "    - Activity Regularizer: Tries to reduce the layer's output 𝑦, thus will reduce the weights and adjust bias so 𝑊𝑥+𝑏 is smallest.\n",
    "\n",
    "- The concept of Batch Normalization (https://www.youtube.com/watch?v=1XMjfhEFbFA)\n",
    " - Consider a deep neural network. In a DNN, we typically use a version of mini-match algorithm to train. This means that we use a batch-size to train our models\n",
    " - What would happen if distribution of inputs change with each batch?\n",
    "    - This is bad because we will have to keep on constantly adjust to the new distribution\n",
    "        - Solution: What if we make the data gaussian at the input of each layer?\n",
    "        - For a mini batch, for input to each layer, apply a normalization function to transform it to 0 mean 1 variance: $ \\hat{S}_i = (S_i - E[S_i])/\\sqrt{var(S_i)}$ \n",
    "        - What if this is not right? How to account for that?\n",
    "        - Provide the freedom to the network to adjust back, if required  i.e. learn the output as  - $y_k   = \\gamma_k * \\hat{S_{ik}} + \\beta_k$ where $y_k$ is the output of the kth layer ; $\\gamma_k , \\beta_k$ are learnable parameters. Meaning, for each layer we will have 2 set of parameters that will be learnt and 2 set of parameters that will not be learnt (mean and variance to apply to the input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 0s 908us/step - loss: 2.6184 - accuracy: 0.3800 - val_loss: 2.2825 - val_accuracy: 0.5543\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 727us/step - loss: 1.9696 - accuracy: 0.6413 - val_loss: 1.6613 - val_accuracy: 0.7250\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 759us/step - loss: 1.4909 - accuracy: 0.7684 - val_loss: 1.3051 - val_accuracy: 0.8264\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 746us/step - loss: 1.2143 - accuracy: 0.8367 - val_loss: 1.0826 - val_accuracy: 0.8673\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 734us/step - loss: 1.0288 - accuracy: 0.8661 - val_loss: 0.9312 - val_accuracy: 0.8880\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 743us/step - loss: 0.8972 - accuracy: 0.8830 - val_loss: 0.8214 - val_accuracy: 0.8992\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 747us/step - loss: 0.8001 - accuracy: 0.8940 - val_loss: 0.7381 - val_accuracy: 0.9069\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 780us/step - loss: 0.7252 - accuracy: 0.9012 - val_loss: 0.6731 - val_accuracy: 0.9128\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 753us/step - loss: 0.6645 - accuracy: 0.9071 - val_loss: 0.6224 - val_accuracy: 0.9151\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 752us/step - loss: 0.6143 - accuracy: 0.9118 - val_loss: 0.5758 - val_accuracy: 0.9199\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 738us/step - loss: 0.5715 - accuracy: 0.9165 - val_loss: 0.5377 - val_accuracy: 0.9244\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 826us/step - loss: 0.5345 - accuracy: 0.9210 - val_loss: 0.5043 - val_accuracy: 0.9275\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 728us/step - loss: 0.5025 - accuracy: 0.9234 - val_loss: 0.4763 - val_accuracy: 0.9302\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 737us/step - loss: 0.4751 - accuracy: 0.9269 - val_loss: 0.4521 - val_accuracy: 0.9314\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 736us/step - loss: 0.4508 - accuracy: 0.9300 - val_loss: 0.4308 - val_accuracy: 0.9345\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 738us/step - loss: 0.4298 - accuracy: 0.9318 - val_loss: 0.4134 - val_accuracy: 0.9351\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 744us/step - loss: 0.4114 - accuracy: 0.9342 - val_loss: 0.3971 - val_accuracy: 0.9368\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 741us/step - loss: 0.3947 - accuracy: 0.9361 - val_loss: 0.3810 - val_accuracy: 0.9386\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 736us/step - loss: 0.3804 - accuracy: 0.9379 - val_loss: 0.3689 - val_accuracy: 0.9402\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 729us/step - loss: 0.3671 - accuracy: 0.9385 - val_loss: 0.3573 - val_accuracy: 0.9403\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 722us/step - loss: 0.3553 - accuracy: 0.9404 - val_loss: 0.3468 - val_accuracy: 0.9435\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 731us/step - loss: 0.3448 - accuracy: 0.9418 - val_loss: 0.3388 - val_accuracy: 0.9426\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 791us/step - loss: 0.3352 - accuracy: 0.9427 - val_loss: 0.3363 - val_accuracy: 0.9423\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 722us/step - loss: 0.3264 - accuracy: 0.9441 - val_loss: 0.3219 - val_accuracy: 0.9442\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 717us/step - loss: 0.3182 - accuracy: 0.9451 - val_loss: 0.3171 - val_accuracy: 0.9460\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.3111 - accuracy: 0.9457 - val_loss: 0.3107 - val_accuracy: 0.9451\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 740us/step - loss: 0.3044 - accuracy: 0.9469 - val_loss: 0.3027 - val_accuracy: 0.9482\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 738us/step - loss: 0.2982 - accuracy: 0.9483 - val_loss: 0.2985 - val_accuracy: 0.9475\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 766us/step - loss: 0.2919 - accuracy: 0.9492 - val_loss: 0.2926 - val_accuracy: 0.9493\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 827us/step - loss: 0.2864 - accuracy: 0.9495 - val_loss: 0.2895 - val_accuracy: 0.9480\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 716us/step - loss: 0.2814 - accuracy: 0.9514 - val_loss: 0.2830 - val_accuracy: 0.9507\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 715us/step - loss: 0.2764 - accuracy: 0.9517 - val_loss: 0.2791 - val_accuracy: 0.9513\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 728us/step - loss: 0.2719 - accuracy: 0.9523 - val_loss: 0.2743 - val_accuracy: 0.9525\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 713us/step - loss: 0.2679 - accuracy: 0.9532 - val_loss: 0.2719 - val_accuracy: 0.9523\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 726us/step - loss: 0.2639 - accuracy: 0.9541 - val_loss: 0.2710 - val_accuracy: 0.9520\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 721us/step - loss: 0.2604 - accuracy: 0.9542 - val_loss: 0.2669 - val_accuracy: 0.9528\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 713us/step - loss: 0.2567 - accuracy: 0.9553 - val_loss: 0.2624 - val_accuracy: 0.9529\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 720us/step - loss: 0.2533 - accuracy: 0.9557 - val_loss: 0.2597 - val_accuracy: 0.9544\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 722us/step - loss: 0.2502 - accuracy: 0.9558 - val_loss: 0.2573 - val_accuracy: 0.9541\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 728us/step - loss: 0.2471 - accuracy: 0.9566 - val_loss: 0.2560 - val_accuracy: 0.9542\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 723us/step - loss: 0.2444 - accuracy: 0.9568 - val_loss: 0.2528 - val_accuracy: 0.9544\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 722us/step - loss: 0.2414 - accuracy: 0.9581 - val_loss: 0.2516 - val_accuracy: 0.9545\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 724us/step - loss: 0.2391 - accuracy: 0.9580 - val_loss: 0.2480 - val_accuracy: 0.9556\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 718us/step - loss: 0.2365 - accuracy: 0.9588 - val_loss: 0.2495 - val_accuracy: 0.9538\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 707us/step - loss: 0.2338 - accuracy: 0.9588 - val_loss: 0.2437 - val_accuracy: 0.9558\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 743us/step - loss: 0.2315 - accuracy: 0.9602 - val_loss: 0.2438 - val_accuracy: 0.9544\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 720us/step - loss: 0.2294 - accuracy: 0.9601 - val_loss: 0.2427 - val_accuracy: 0.9552\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 760us/step - loss: 0.2274 - accuracy: 0.9602 - val_loss: 0.2411 - val_accuracy: 0.9554\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 717us/step - loss: 0.2252 - accuracy: 0.9603 - val_loss: 0.2339 - val_accuracy: 0.9575\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 818us/step - loss: 0.2229 - accuracy: 0.9606 - val_loss: 0.2360 - val_accuracy: 0.9575\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l1,l2\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (784,)),\n",
    "        layers.Dense(units = 32, activation = 'relu', name = 'D1', kernel_regularizer = l2(0.01), activity_regularizer = l2(0.01), bias_regularizer = l1(0.01)),\n",
    "        layers.Dense(units = 16, activation = 'relu', name = 'D2'),\n",
    "\n",
    "        layers.Dense(units = 10, activation = 'softmax', name = 'D3')\n",
    "    ]\n",
    "    )\n",
    "model.compile(optimizer = 'SGD', loss =  'categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "m6 = model.fit(X_train, Y_train, validation_split = 0.2, batch_size = 128, epochs = 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " D1 (Dense)                  (None, 32)                25120     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " D2 (Dense)                  (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " D3 (Dense)                  (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26010 (101.60 KB)\n",
      "Trainable params: 25914 (101.23 KB)\n",
      "Non-trainable params: 96 (384.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (784,)),\n",
    "        \n",
    "        layers.Dense(units = 32, activation = 'relu', name = 'D1'),\n",
    "        BatchNormalization(),\n",
    "        layers.Dense(units = 16, activation = 'relu', name = 'D2'),\n",
    "        BatchNormalization(),\n",
    "        layers.Dense(units = 10, activation = 'softmax', name = 'D3')\n",
    "    ]\n",
    "    )\n",
    "model.compile(optimizer = 'SGD', loss =  'categorical_crossentropy', metrics = 'accuracy')\n",
    "print(model.summary())\n",
    "# m7 = model.fit(X_train, Y_train, validation_split = 0.2, batch_size = 128, epochs = 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, the batchnormalization layer has output shape same as the output shape of the layer on which it is applied. It has 4* number of units as parameters. \n",
    " - 2 * num of units are trainable parameters: These are the $\\gamma$ and $\\beta$ we mentioned above\n",
    " - 2* num of units are the moving average means and variance that are recorded and stored for each unit in a layer to use at inference time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.0555 - accuracy: 0.7071 - val_loss: 0.6678 - val_accuracy: 0.8506\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 839us/step - loss: 0.5459 - accuracy: 0.8646 - val_loss: 0.4241 - val_accuracy: 0.8949\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 972us/step - loss: 0.4095 - accuracy: 0.8945 - val_loss: 0.3424 - val_accuracy: 0.9097\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 835us/step - loss: 0.3403 - accuracy: 0.9081 - val_loss: 0.2973 - val_accuracy: 0.9214\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 859us/step - loss: 0.2964 - accuracy: 0.9201 - val_loss: 0.2690 - val_accuracy: 0.9277\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 863us/step - loss: 0.2680 - accuracy: 0.9256 - val_loss: 0.2454 - val_accuracy: 0.9326\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 882us/step - loss: 0.2454 - accuracy: 0.9310 - val_loss: 0.2332 - val_accuracy: 0.9358\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 835us/step - loss: 0.2276 - accuracy: 0.9356 - val_loss: 0.2183 - val_accuracy: 0.9402\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 848us/step - loss: 0.2130 - accuracy: 0.9390 - val_loss: 0.2076 - val_accuracy: 0.9421\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 827us/step - loss: 0.2007 - accuracy: 0.9428 - val_loss: 0.1988 - val_accuracy: 0.9452\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 885us/step - loss: 0.1909 - accuracy: 0.9445 - val_loss: 0.1896 - val_accuracy: 0.9483\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 830us/step - loss: 0.1797 - accuracy: 0.9485 - val_loss: 0.1837 - val_accuracy: 0.9499\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 834us/step - loss: 0.1726 - accuracy: 0.9499 - val_loss: 0.1786 - val_accuracy: 0.9510\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 832us/step - loss: 0.1644 - accuracy: 0.9530 - val_loss: 0.1731 - val_accuracy: 0.9523\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 822us/step - loss: 0.1574 - accuracy: 0.9546 - val_loss: 0.1688 - val_accuracy: 0.9543\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 829us/step - loss: 0.1506 - accuracy: 0.9560 - val_loss: 0.1649 - val_accuracy: 0.9538\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 831us/step - loss: 0.1447 - accuracy: 0.9581 - val_loss: 0.1628 - val_accuracy: 0.9542\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 822us/step - loss: 0.1407 - accuracy: 0.9586 - val_loss: 0.1598 - val_accuracy: 0.9557\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 816us/step - loss: 0.1342 - accuracy: 0.9615 - val_loss: 0.1558 - val_accuracy: 0.9553\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 876us/step - loss: 0.1318 - accuracy: 0.9624 - val_loss: 0.1538 - val_accuracy: 0.9567\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 846us/step - loss: 0.1272 - accuracy: 0.9634 - val_loss: 0.1517 - val_accuracy: 0.9562\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 864us/step - loss: 0.1236 - accuracy: 0.9647 - val_loss: 0.1504 - val_accuracy: 0.9569\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 877us/step - loss: 0.1198 - accuracy: 0.9646 - val_loss: 0.1482 - val_accuracy: 0.9571\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 842us/step - loss: 0.1159 - accuracy: 0.9661 - val_loss: 0.1469 - val_accuracy: 0.9575\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 833us/step - loss: 0.1134 - accuracy: 0.9666 - val_loss: 0.1446 - val_accuracy: 0.9589\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 824us/step - loss: 0.1095 - accuracy: 0.9674 - val_loss: 0.1445 - val_accuracy: 0.9582\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 824us/step - loss: 0.1080 - accuracy: 0.9688 - val_loss: 0.1451 - val_accuracy: 0.9584\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 821us/step - loss: 0.1050 - accuracy: 0.9694 - val_loss: 0.1440 - val_accuracy: 0.9603\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 823us/step - loss: 0.1006 - accuracy: 0.9704 - val_loss: 0.1431 - val_accuracy: 0.9579\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 799us/step - loss: 0.0990 - accuracy: 0.9711 - val_loss: 0.1385 - val_accuracy: 0.9590\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 803us/step - loss: 0.0972 - accuracy: 0.9709 - val_loss: 0.1404 - val_accuracy: 0.9584\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 819us/step - loss: 0.0955 - accuracy: 0.9721 - val_loss: 0.1387 - val_accuracy: 0.9601\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 814us/step - loss: 0.0925 - accuracy: 0.9730 - val_loss: 0.1377 - val_accuracy: 0.9598\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 795us/step - loss: 0.0912 - accuracy: 0.9736 - val_loss: 0.1369 - val_accuracy: 0.9602\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 820us/step - loss: 0.0894 - accuracy: 0.9739 - val_loss: 0.1362 - val_accuracy: 0.9580\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 896us/step - loss: 0.0864 - accuracy: 0.9748 - val_loss: 0.1374 - val_accuracy: 0.9597\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 830us/step - loss: 0.0839 - accuracy: 0.9755 - val_loss: 0.1353 - val_accuracy: 0.9618\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 866us/step - loss: 0.0841 - accuracy: 0.9754 - val_loss: 0.1349 - val_accuracy: 0.9613\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 843us/step - loss: 0.0827 - accuracy: 0.9755 - val_loss: 0.1357 - val_accuracy: 0.9607\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 816us/step - loss: 0.0803 - accuracy: 0.9766 - val_loss: 0.1343 - val_accuracy: 0.9617\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 910us/step - loss: 0.0790 - accuracy: 0.9770 - val_loss: 0.1342 - val_accuracy: 0.9607\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 814us/step - loss: 0.0771 - accuracy: 0.9779 - val_loss: 0.1357 - val_accuracy: 0.9605\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 817us/step - loss: 0.0761 - accuracy: 0.9780 - val_loss: 0.1336 - val_accuracy: 0.9600\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 818us/step - loss: 0.0762 - accuracy: 0.9779 - val_loss: 0.1342 - val_accuracy: 0.9608\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 871us/step - loss: 0.0730 - accuracy: 0.9789 - val_loss: 0.1329 - val_accuracy: 0.9615\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 825us/step - loss: 0.0714 - accuracy: 0.9790 - val_loss: 0.1350 - val_accuracy: 0.9607\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 817us/step - loss: 0.0711 - accuracy: 0.9793 - val_loss: 0.1312 - val_accuracy: 0.9619\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 830us/step - loss: 0.0700 - accuracy: 0.9803 - val_loss: 0.1315 - val_accuracy: 0.9618\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 837us/step - loss: 0.0687 - accuracy: 0.9801 - val_loss: 0.1332 - val_accuracy: 0.9615\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 872us/step - loss: 0.0684 - accuracy: 0.9806 - val_loss: 0.1305 - val_accuracy: 0.9620\n"
     ]
    }
   ],
   "source": [
    "m7 = model.fit(X_train, Y_train, validation_split = 0.2, batch_size = 128, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x374977cd0>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 20000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (200,5))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(m1.history['val_accuracy'], label = 'dense layer')\n",
    "ax.plot(m0.history['val_accuracy'], label  = 'no dense layer')\n",
    "ax.plot(m2.history['val_accuracy'], label  = 'two  dense layer SGD')\n",
    "ax.plot(m3.history['val_accuracy'], label  = 'two  dense layer and dropout')\n",
    "ax.plot(m4.history['val_accuracy'], label  = 'two  dense layer Adam')\n",
    "ax.plot(m5.history['val_accuracy'], label  = 'two  dense layer RMSProp')\n",
    "ax.plot(m6.history['val_accuracy'], label  = 'two  dense layer SGD regularization')\n",
    "ax.plot(m7.history['val_accuracy'], label  = 'two  dense layer with Batch Norm and SGD')\n",
    "\n",
    "ax.set_ylabel('Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train,Y_train), (X_test, Y_test) = keras.datasets.imdb.load_data(num_words = 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=  (25000,) , X_test.shape = (25000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{X_train.shape=  } , {X_test.shape = }\"  )\n",
    "\n",
    "# This is how each record in the X_train looks like\n",
    "# each word is represented by the word frequency. Meaning the second word in the ```X_train[0]``` is 14th most frequent word in the corpus\n",
    "X_train[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default parameters to keras.datasets.imdb.load_data\n",
    "start_char = 1 # This character is used to symbolize that here will the review start from \n",
    "oov_char = 2 # This indicates whether a character is absent from the vocabulary\n",
    "index_from = 3\n",
    "# Retrieve the training sequences.\n",
    "(x_train, _), _ = keras.datasets.imdb.load_data(\n",
    "    start_char=start_char, oov_char=oov_char, index_from=index_from\n",
    ")\n",
    "# Retrieve the word index file mapping words to indices\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "# And add `index_from` to indices to sync with `x_train`\n",
    "# since we have designated the index 1 and 2 to start and OOV\n",
    "inverted_word_index = dict(\n",
    "    (i + index_from, word) for (word, i) in word_index.items()\n",
    ")\n",
    "# Update `inverted_word_index` to include `start_char` and `oov_char`\n",
    "inverted_word_index[start_char] = \"[START]\"\n",
    "inverted_word_index[oov_char] = \"[OOV]\"\n",
    "# Decode the first sequence in the dataset\n",
    "def decode(inp: list):    \n",
    "    decoded_sequence = \" \".join(inverted_word_index[i] for i in inp)\n",
    "    return decoded_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had [OOV] working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how [OOV] this is to watch save yourself an hour a bit of your life \n",
      "\n",
      "[START] begins better than it ends funny that the russian submarine crew [OOV] all other actors it's like those scenes where documentary shots br br spoiler part the message [OOV] was contrary to the whole story it just does not [OOV] br br \n",
      "\n",
      "[START] the [OOV] tells the story of the four hamilton siblings teenager francis [OOV] [OOV] twins [OOV] joseph [OOV] [OOV] [OOV] [OOV] the [OOV] david samuel who is now the surrogate parent in charge the [OOV] move house a lot [OOV] is unsure why is unhappy with the way things are the fact that his brother's sister kidnap [OOV] murder people in the basement doesn't help relax or calm [OOV] nerves either francis [OOV] something just isn't right when he eventually finds out the truth things will never be the same again br br co written co produced directed by mitchell [OOV] phil [OOV] as the butcher brothers who's only other film director's credit so far is the april [OOV] day 2008 remake enough said this was one of the [OOV] to die [OOV] at the 2006 after dark [OOV] or whatever it's called in keeping with pretty much all the other's i've seen i thought the [OOV] was complete total utter crap i found the character's really poor very unlikable the slow moving story failed to capture my imagination or sustain my interest over it's 85 a half minute too long [OOV] minute duration the there's the awful twist at the end which had me laughing out loud there's this really big [OOV] build up to what's inside a [OOV] thing in the [OOV] basement it's eventually revealed to be a little boy with a teddy is that really supposed to scare us is that really supposed to shock us is that really something that is supposed to have us talking about it as the end credits roll is a harmless looking young boy the best [OOV] ending that the makers could come up with the boring plot [OOV] along it's never made clear where the [OOV] get all their money from to buy new houses since none of them seem to work except david in a [OOV] i doubt that pays much or why they haven't been caught before now the script tries to mix in every day drama with potent horror it just does a terrible job of combining the two to the extent that neither aspect is memorable or effective a really bad film that i am struggling to say anything good about br br despite being written directed by the extreme sounding butcher brothers there's no gore here there's a bit of blood splatter a few scenes of girls [OOV] up in a basement but nothing you couldn't do at home yourself with a bottle of [OOV] [OOV] a camcorder the film is neither scary since it's got a very middle class suburban setting there's zero atmosphere or mood there's a lesbian suggest incestuous kiss but the [OOV] is low on the exploitation scale there's not much here for the horror crowd br br filmed in [OOV] in california this has that modern low budget look about it it's not badly made but rather forgettable the acting by an unknown to me cast is nothing to write home about i can't say i ever felt anything for anyone br br the [OOV] commits the [OOV] sin of being both dull boring from which it never [OOV] add to that an ultra thin story no gore a rubbish ending character's who you don't give a toss about you have a film that did not impress me at all \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,7]:\n",
    "    print(decode(X_train[i]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of first 5 comments [218, 189, 141, 550, 147]\n",
      "\n",
      "len(X_train[0])=218\n"
     ]
    }
   ],
   "source": [
    "# Input will be fed into a neural network and the lengths of the input should be same.\n",
    "print(f\"len of first 5 comments {[len(x) for x in X_train][0:5]}\\n\")\n",
    "\n",
    "# padding is done using the tf.keras.preprocessing --> It is similar to sklearn preprocessing stuff\n",
    "X_train_padded = keras.preprocessing.sequence.pad_sequences(sequences = X_train,maxlen=200)\n",
    "X_test_padded  = keras.preprocessing.sequence.pad_sequences(sequences = X_test,maxlen=200)\n",
    "\n",
    "# lets understand the padding\n",
    "# for one where len > max_len\n",
    "# in such cases first n-maxlen elements are chipped off of the array\n",
    "assert np.all(np.equal(np.array(X_train_padded[0,:]), np.array(X_train[0][len(X_train[0])- 200:])))\n",
    "# for one where len < max_len\n",
    "# They are padded with zeros in the beginning\n",
    "assert np.all(X_train[1] == X_train_padded[1,200-len((X_train[1])):])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the concept of embedding layer\n",
    " - Embedding layer is similar to a lookup table. \n",
    " - The embeddings are learn in the process of accomplishing a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (2,)),\n",
    "        Embedding(input_dim=2, output_dim=20, input_length=)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membeddings_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membeddings_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmask_zero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Turns positive integers (indexes) into dense vectors of fixed size.\n",
      "\n",
      "e.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\n",
      "\n",
      "This layer can only be used on positive integer inputs of a fixed range. The\n",
      "`tf.keras.layers.TextVectorization`, `tf.keras.layers.StringLookup`,\n",
      "and `tf.keras.layers.IntegerLookup` preprocessing layers can help prepare\n",
      "inputs for an `Embedding` layer.\n",
      "\n",
      "This layer accepts `tf.Tensor`, `tf.RaggedTensor` and `tf.SparseTensor`\n",
      "input.\n",
      "\n",
      "Example:\n",
      "\n",
      ">>> model = tf.keras.Sequential()\n",
      ">>> model.add(tf.keras.layers.Embedding(1000, 64, input_length=10))\n",
      ">>> # The model will take as input an integer matrix of size (batch,\n",
      ">>> # input_length), and the largest integer (i.e. word index) in the input\n",
      ">>> # should be no larger than 999 (vocabulary size).\n",
      ">>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
      ">>> # dimension.\n",
      ">>> input_array = np.random.randint(1000, size=(32, 10))\n",
      ">>> model.compile('rmsprop', 'mse')\n",
      ">>> output_array = model.predict(input_array)\n",
      ">>> print(output_array.shape)\n",
      "(32, 10, 64)\n",
      "\n",
      "Args:\n",
      "  input_dim: Integer. Size of the vocabulary,\n",
      "    i.e. maximum integer index + 1.\n",
      "  output_dim: Integer. Dimension of the dense embedding.\n",
      "  embeddings_initializer: Initializer for the `embeddings`\n",
      "    matrix (see `keras.initializers`).\n",
      "  embeddings_regularizer: Regularizer function applied to\n",
      "    the `embeddings` matrix (see `keras.regularizers`).\n",
      "  embeddings_constraint: Constraint function applied to\n",
      "    the `embeddings` matrix (see `keras.constraints`).\n",
      "  mask_zero: Boolean, whether or not the input value 0 is a special\n",
      "    \"padding\" value that should be masked out. This is useful when using\n",
      "    recurrent layers which may take variable length input. If this is\n",
      "    `True`, then all subsequent layers in the model need to support masking\n",
      "    or an exception will be raised. If mask_zero is set to True, as a\n",
      "    consequence, index 0 cannot be used in the vocabulary (input_dim should\n",
      "    equal size of vocabulary + 1).\n",
      "  input_length: Length of input sequences, when it is constant.\n",
      "    This argument is required if you are going to connect\n",
      "    `Flatten` then `Dense` layers upstream\n",
      "    (without it, the shape of the dense outputs cannot be computed).\n",
      "  sparse: If True, calling this layer returns a `tf.SparseTensor`. If False,\n",
      "    the layer returns a dense `tf.Tensor`. For an entry with no features in\n",
      "    a sparse tensor (entry with value 0), the embedding vector of index 0 is\n",
      "    returned by default.\n",
      "\n",
      "Input shape:\n",
      "  2D tensor with shape: `(batch_size, input_length)`.\n",
      "\n",
      "Output shape:\n",
      "  3D tensor with shape: `(batch_size, input_length, output_dim)`.\n",
      "\n",
      "**Note on variable placement:**\n",
      "By default, if a GPU is available, the embedding matrix will be placed on\n",
      "the GPU. This achieves the best performance, but it might cause issues:\n",
      "\n",
      "- You may be using an optimizer that does not support sparse GPU kernels.\n",
      "In this case you will see an error upon training your model.\n",
      "- Your embedding matrix may be too large to fit on your GPU. In this case\n",
      "you will see an Out Of Memory (OOM) error.\n",
      "\n",
      "In such cases, you should place the embedding matrix on the CPU memory.\n",
      "You can do so with a device scope, as such:\n",
      "\n",
      "```python\n",
      "with tf.device('cpu:0'):\n",
      "  embedding_layer = Embedding(...)\n",
      "  embedding_layer.build()\n",
      "```\n",
      "\n",
      "The pre-built `embedding_layer` instance can then be added to a `Sequential`\n",
      "model (e.g. `model.add(embedding_layer)`), called in a Functional model\n",
      "(e.g. `x = embedding_layer(x)`), or used in a subclassed model.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Documents/Sahil_Work/Deep Learning/.venv/lib/python3.11/site-packages/keras/src/layers/core/embedding.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?Embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da1fda02e7ca0cbcc4168dd1e24c69e3acc43f0a3a4d7789f2759cd061eab153"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
